{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3e61a18",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d8dc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "random_state = int(random.random()*1e9)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel, WhiteKernel\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "\n",
    "import sys\n",
    "sys.path.append('/'.join(os.getcwd().split('/')[:-1]))\n",
    "sys.path.append('/'.join(os.getcwd().split('/')[:-2]))\n",
    "\n",
    "from tensor_completion_models.ETC import ETC\n",
    "from tensor_completion_models.utils import *\n",
    "from tensor_completion_models.ensemble_costco import ensemble_costco as EnT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9412117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, col, target):\n",
    "    dummies = pd.get_dummies(df[col], prefix=col)\n",
    "    r_df = pd.concat([dummies.astype(int), df.drop(columns=[col])], axis=1)\n",
    "    r_df = r_df[[c for c in r_df.columns if c != target] + [target]]\n",
    "    return r_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702ae64d",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3414c3",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40e88be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2401e33b",
   "metadata": {},
   "source": [
    "### Setup Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee32547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e251cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    'lattice',\n",
    "    'crossed_barrel',\n",
    "    'cogni_spin'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23077791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "149 115 \n",
      "\n",
      "Random Seed = 821460\n",
      "Random Seed = 745511\n",
      "Random Seed = 391005\n"
     ]
    }
   ],
   "source": [
    "all_train_test_splits = list()\n",
    "for dataset in datasets:\n",
    "    t = 'none' if dataset == 'cogni_spin' else 'log'\n",
    "    # t = 'log'\n",
    "\n",
    "    if dataset == 'lattice':\n",
    "        df = pd.read_csv(f'{data_folder}database_latticedesign.csv')\n",
    "        features = ['lattice_type', 't', 'uc_x1', 'uc_x2', 'uc_x3']\n",
    "\n",
    "        targets = [\n",
    "            'E (MPa)',\n",
    "            'E_specific (MPa/g)'\n",
    "            ]\n",
    "\n",
    "        if len(targets) > 1:\n",
    "            df_list = list()\n",
    "            for ti in range(len(targets)): \n",
    "                sub_df = df[features + [targets[ti]]].to_numpy()\n",
    "                sub_df = np.concatenate((ti*np.ones((sub_df.shape[0], 1)), \n",
    "                                        sub_df), \n",
    "                                        axis = 1)\n",
    "\n",
    "                df_list.append(sub_df)\n",
    "\n",
    "            target = 'target'\n",
    "            df = pd.DataFrame(np.concatenate(df_list), columns = ['task'] + features + [target])\n",
    "            features = [x for x in list(df.columns) if x != target]\n",
    "        else:\n",
    "            target = targets[0]\n",
    "            df = df[features + [target]]\n",
    "\n",
    "    elif dataset == 'crossed_barrel':\n",
    "        df = pd.read_csv(f'{data_folder}crossed_barrel_dataset_v2.csv')\n",
    "        features = ['n', 'theta', 'r', 't']\n",
    "        targets = ['toughness']\n",
    "        target = targets[0]\n",
    "        df = df[features + [target]]\n",
    "        df = df.groupby(features, as_index=False).agg(target=(target, 'median'))\n",
    "        target = 'target'\n",
    "\n",
    "    elif dataset.lower() == 'cogni_spin':\n",
    "        df = pd.read_csv(f'{data_folder}Cogni-e-SpinDB 1.0.csv')\n",
    "\n",
    "        features = ['solution_concentration', 'voltage_kv', 'flow_rate_ml/h', 'tip_collector_distance_cm',\n",
    "                    'polymer(s)']\n",
    "        # features += ['needle_diameter_g']  # ~50% missing values!\n",
    "\n",
    "        target = 'fiber_diameter_nm'\n",
    "\n",
    "        df = df[df['polymer(s)'].map(lambda x: x in ['PVDF', 'PVA', 'PAN'])]\n",
    "        codes, uniques = pd.factorize(df[\"polymer(s)\"])\n",
    "        df['polymer(s)'] = codes\n",
    "\n",
    "        df = df[features + [target]].dropna()\n",
    "\n",
    "        mask = (df['flow_rate_ml/h'] < 5) & (df['tip_collector_distance_cm'] < 45) & (df['voltage_kv'] < 40)\n",
    "        df = df[mask]\n",
    "\n",
    "    df = (\n",
    "        df.groupby(features, as_index=False)\n",
    "        .agg(\n",
    "            value_mean=(target, 'mean'),\n",
    "            target_std=(target, 'std'),\n",
    "            target_min=(target, 'min'),\n",
    "            target_max=(target, 'max'),\n",
    "            num_duplicates=(target, 'count')\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df['target_std'] = df['target_std'].fillna(0)\n",
    "    df.columns = [x if x != 'value_mean' else target for x in df.columns]\n",
    "\n",
    "    df = df[df['target_std'] == 0]\n",
    "\n",
    "    df = df[df.columns[:-4]]\n",
    "\n",
    "    ts = {\n",
    "        'none': lambda x: x,\n",
    "        'log': lambda x: np.log(x),\n",
    "        'sqrt': lambda x: np.sqrt(x),\n",
    "        'loglog': lambda x: np.log( np.log(x) )\n",
    "    }\n",
    "    t = ts[t]\n",
    "\n",
    "    df[target] = t(df[target])\n",
    "\n",
    "    round_ = None\n",
    "    if type(round_) in [float, int]: round_ = {feature:round_ for feature in features}\n",
    "    elif round_ is not None:\n",
    "        for feature in features:\n",
    "            if feature not in round_: round_[feature] = round_['default']\n",
    "    tensor_df = df.copy()\n",
    "    for feature in features:\n",
    "        if round_ is not None: unique = (tensor_df[feature]//round_[feature]).unique()\n",
    "        else: unique = tensor_df[feature].unique()\n",
    "        unique = np.sort(unique)\n",
    "        conv = {unique[i]:i for i in range(len(unique))}\n",
    "        if round_ is not None: tensor_df[feature] = (tensor_df[feature]//round_[feature]).map(lambda x: conv[x])\n",
    "        else: tensor_df[feature] = tensor_df[feature].map(lambda x: conv[x])\n",
    "\n",
    "    tensor_shape = torch.Size([tensor_df[feature].max()+1 for feature in features])\n",
    "\n",
    "    indices = tensor_df[features].to_numpy()\n",
    "    indices = torch.tensor(indices, dtype = torch.int32)\n",
    "    values = torch.tensor(tensor_df[target].to_numpy())\n",
    "\n",
    "    sparse_tensor = torch.sparse_coo_tensor(indices = indices.t(), \n",
    "                                            values = values, \n",
    "                                            size = tensor_shape\n",
    "                                        ).coalesce()\n",
    "\n",
    "    if 'lattice_type' in df.columns: df = one_hot_encode(df, 'lattice_type', target)\n",
    "    if 'polymer(s)' in df.columns: df = one_hot_encode(df, 'polymer(s)', target)\n",
    "\n",
    "    features = [x for x in df.columns if x != target]    \n",
    "\n",
    "    if dataset == 'lattice':\n",
    "        n_in,  n_out = 50, 5\n",
    "        c1 = 'lattice_type'\n",
    "        c2 = 't'\n",
    "        # condition = ((tensor_df[c1] == 0) | (tensor_df[c1] == 1)) & (tensor_df[c2] == 1)\n",
    "\n",
    "        c1_low, c1_high = 0, 1\n",
    "        c2_low, c2_high = 1, 1\n",
    "        condition = (tensor_df[c1] >= c1_low) & (tensor_df[c1] <= c1_high) & (tensor_df[c2] >= c2_low) & (tensor_df[c2] <= c2_high)\n",
    "\n",
    "    if dataset == 'crossed_barrel':\n",
    "\n",
    "        n_in,  n_out = 150, 75\n",
    "        c1 = 'n'\n",
    "        c2 = 't'\n",
    "        # condition = (tensor_df[c1] <= 1) & (tensor_df[c2] == 1)\n",
    "\n",
    "        c1_low, c1_high = 0, 1\n",
    "        c2_low, c2_high = 1, 2\n",
    "        condition = (tensor_df[c1] >= c1_low) & (tensor_df[c1] <= c1_high) & (tensor_df[c2] >= c2_low) & (tensor_df[c2] <= c2_high)\n",
    "\n",
    "    if dataset == 'cogni_spin':\n",
    "        # n_in,  n_out = 75, 35\n",
    "        n_in, n_out = 140, 40\n",
    "        c1 = 'flow_rate_ml/h'\n",
    "        c2 = 'voltage_kv'\n",
    "\n",
    "        c1_low, c1_high = 0, 8\n",
    "        c2_low, c2_high = 10, 18\n",
    "        condition = (tensor_df[c1] >= c1_low) & (tensor_df[c1] <= c1_high) & (tensor_df[c2] >= c2_low) & (tensor_df[c2] <= c2_high)\n",
    "\n",
    "    train_test_splits = list()\n",
    "    for _ in range(n_splits):\n",
    "\n",
    "        df1 = df[condition]\n",
    "        df2 = df[~condition]\n",
    "        if _ == 0: print('\\n' + str(df1.shape[0]), str(df2.shape[0]), '\\n')\n",
    "\n",
    "        df1_i = list(df1.index)\n",
    "        df2_i = list(df2.index)\n",
    "\n",
    "        random_seed = int(1_000_000 * random.random())\n",
    "        random.seed(random_seed)\n",
    "        \n",
    "        print(f\"Random Seed = {random_seed}\")\n",
    "\n",
    "        random.shuffle(df1_i)\n",
    "        random.shuffle(df2_i)\n",
    "\n",
    "        train_i = df1_i[:n_in] + df2_i[:n_out]\n",
    "        test_i = df1_i[n_in:] + df2_i[n_out:]\n",
    "\n",
    "        test_ood_i = df2_i[n_out:]\n",
    "        test_ood_df = df.loc[test_ood_i].sample(frac = 1, random_state = random_state).reset_index(drop = True)\n",
    "        tensor_test_ood_df = tensor_df.loc[test_ood_i].sample(frac = 1, random_state = random_state).reset_index(drop = True)\n",
    "\n",
    "        # ________________________________________________________________________________________________________________\n",
    "\n",
    "        train_df = df.loc[train_i].sample(frac = 1, random_state = random_state).reset_index(drop = True)\n",
    "        test_df = df.loc[test_i].sample(frac = 1, random_state = random_state).reset_index(drop = True)\n",
    "        X_train = train_df[[c for c in train_df.columns if c != target]].to_numpy()\n",
    "        Y_train = train_df[target].to_numpy()\n",
    "\n",
    "        X_test = test_df[[c for c in train_df.columns if c != target]].to_numpy()\n",
    "        Y_test = test_df[target].to_numpy()\n",
    "\n",
    "        X_test_ood = test_ood_df[[c for c in train_df.columns if c != target]].to_numpy()\n",
    "        Y_test_ood = test_ood_df[target].to_numpy()\n",
    "\n",
    "        X = np.concatenate((X_train, X_test))\n",
    "        X_train = (X_train - X.min(axis = 0)) / (X.max(axis = 0) - X.min(axis = 0))\n",
    "        X_test = (X_test - X.min(axis = 0)) / (X.max(axis = 0) - X.min(axis = 0))\n",
    "        X_test_ood = (X_test_ood - X.min(axis = 0)) / (X.max(axis = 0) - X.min(axis = 0))\n",
    "        del X\n",
    "\n",
    "        Y_test = (Y_test - Y_train.min()) / (Y_train.max() - Y_train.min())\n",
    "        Y_test_ood = (Y_test_ood - Y_train.min()) / (Y_train.max() - Y_train.min())\n",
    "        Y_train = (Y_train - Y_train.min()) / (Y_train.max() - Y_train.min())\n",
    "\n",
    "        # ________________________________________________________________________________________________________________\n",
    "\n",
    "        tensor_train_df = tensor_df.loc[train_i].sample(frac = 1, random_state = random_state).reset_index(drop = True)\n",
    "        tensor_test_df = tensor_df.loc[test_i].sample(frac = 1, random_state = random_state).reset_index(drop = True)\n",
    "\n",
    "        tFeatures = [c for c in tensor_test_df.columns if c != target]\n",
    "\n",
    "        tX_train = torch.tensor(tensor_train_df[tFeatures].to_numpy(), dtype = torch.int32).t()\n",
    "        tX_test = torch.tensor(tensor_test_df[tFeatures].to_numpy(), dtype = torch.int32).t()\n",
    "        tX_test_ood = torch.tensor(tensor_test_ood_df[tFeatures].to_numpy(), dtype = torch.int32)\n",
    "\n",
    "        tY_train = torch.tensor(tensor_train_df[target].to_numpy())\n",
    "        tY_test = torch.tensor(tensor_test_df[target].to_numpy())\n",
    "        tY_test_ood = torch.tensor(tensor_test_ood_df[target].to_numpy())\n",
    "\n",
    "        tY_test = (tY_test - tY_train.min()) / (tY_train.max() - tY_train.min())\n",
    "        tY_test_ood = (tY_test_ood - tY_train.min()) / (tY_train.max() - tY_train.min())\n",
    "        tY_train = (tY_train - tY_train.min()) / (tY_train.max() - tY_train.min())\n",
    "\n",
    "        training_sparse_tensor = torch.sparse_coo_tensor(indices = tX_train,\n",
    "                                                        values = tY_train, \n",
    "                                                        size = tensor_shape\n",
    "                                                        ).coalesce()\n",
    "\n",
    "        testing_sparse_tensor = torch.sparse_coo_tensor(indices = tX_test, \n",
    "                                                        values = tY_test, \n",
    "                                                        size = tensor_shape\n",
    "                                                        ).coalesce()\n",
    "\n",
    "        # ________________________________________________________________________________________________________________\n",
    "\n",
    "        train_test_splits.append({\n",
    "            'ML':(X_train, X_test, Y_train, Y_test),\n",
    "            'Tensor':(training_sparse_tensor, testing_sparse_tensor),\n",
    "            'Test_OOD':(X_test_ood, Y_test_ood, tX_test_ood, tY_test_ood),\n",
    "        })\n",
    "\n",
    "    all_train_test_splits.append({\n",
    "        'dataset':dataset,\n",
    "        'tensor_shape':tensor_shape,\n",
    "        'train_test_splits':train_test_splits\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f6cf50",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c837346",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48bcccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results():\n",
    "    \n",
    "    all_results = list()\n",
    "    all_preds = list()\n",
    "    \n",
    "    for dataset_dict in all_train_test_splits:\n",
    "\n",
    "        dataset = dataset_dict['dataset']\n",
    "        tensor_shape = dataset_dict['tensor_shape']\n",
    "        train_test_splits = dataset_dict['train_test_splits']\n",
    "\n",
    "        it_list = list()\n",
    "        pred_it_list = list()\n",
    "\n",
    "        print(f\"Dataset: {dataset}\")\n",
    "        print(\"Iteration:\", end = \" \")\n",
    "        for it in range(len(train_test_splits)):\n",
    "\n",
    "            random_state = int(random.random()*100_000)\n",
    "            training_sparse_tensor, testing_sparse_tensor = train_test_splits[it]['Tensor']\n",
    "            X_train, X_test, Y_train, Y_test = train_test_splits[it]['ML']\n",
    "            tY_test = testing_sparse_tensor.values().numpy()\n",
    "            X_test_ood, Y_test_ood, tX_test_ood, tY_test_ood = train_test_splits[it]['Test_OOD']\n",
    "            tY_test_ood = tY_test_ood.numpy()\n",
    "\n",
    "            metric_list = list()\n",
    "            pred_list = list()\n",
    "\n",
    "            # ________________________________________________________________________________________________________________________\n",
    "\n",
    "            cpd = train_tensor_completion(model_type = 'cpd',\n",
    "                                        rank = {'lattice':32, 'crossed_barrel':4, 'cogni_spin':6}[dataset],\n",
    "                                        sparse_tensor = training_sparse_tensor,\n",
    "                                        num_epochs = 500,\n",
    "                                        batch_size = 96,\n",
    "                                        loss_p = 2,\n",
    "                                        lr = 1e-3,\n",
    "                                        wd = 1e-4,\n",
    "                                        val_size = None,\n",
    "                                        early_stopping = False,\n",
    "                                        verbose = False)\n",
    "\n",
    "            preds = cpd(testing_sparse_tensor.indices().t()).detach().cpu().numpy()\n",
    "            r2 = r2_score(tY_test, preds)\n",
    "            mae = abs(preds - tY_test).mean()\n",
    "            r_mse = (abs((preds - tY_test) ** 2).mean()) ** (1/2)\n",
    "            mape = abs((preds - tY_test) / tY_test).mean()\n",
    "            smape = abs( 2 * ((preds - tY_test) / (abs(tY_test) + abs(preds)))).mean()\n",
    "\n",
    "            ood_preds = cpd(tX_test_ood).detach().cpu().numpy()\n",
    "            ood_mae = abs(ood_preds - tY_test_ood).mean()\n",
    "\n",
    "            metric_list.append([r2, mae, r_mse, mape, smape, ood_mae])\n",
    "            pred_list.append([preds, tY_test])\n",
    "            del cpd, preds, r2, mae\n",
    "\n",
    "            # ________________________________________________________________________________________________________________________\n",
    "\n",
    "            cpd_s = train_tensor_completion(model_type = 'cpd.smooth',\n",
    "                                            rank = {'lattice':24, 'crossed_barrel':6, 'cogni_spin':4}[dataset],\n",
    "                                            sparse_tensor = training_sparse_tensor,\n",
    "                                            non_smooth_modes = {'lattice':[0], 'crossed_barrel':[], 'cogni_spin':[0, 4]}[dataset],\n",
    "                                            num_epochs = 500,\n",
    "                                            batch_size = 96,\n",
    "                                            loss_p = 2,\n",
    "                                            lr = 1e-3,\n",
    "                                            wd = 1e-4,\n",
    "                                            val_size = None,\n",
    "                                            early_stopping = False,\n",
    "                                            verbose = False)\n",
    "\n",
    "            preds = cpd_s(testing_sparse_tensor.indices().t()).detach().cpu().numpy()\n",
    "            r2 = r2_score(tY_test, preds)\n",
    "            mae = abs(preds - tY_test).mean()\n",
    "            r_mse = (abs((preds - tY_test) ** 2).mean()) ** (1/2)\n",
    "            mape = abs((preds - tY_test) / tY_test).mean()\n",
    "            smape = abs( 2 * ((preds - tY_test) / (abs(tY_test) + abs(preds)))).mean()\n",
    "\n",
    "            ood_preds = cpd_s(tX_test_ood).detach().cpu().numpy()\n",
    "            ood_mae = abs(ood_preds - tY_test_ood).mean()\n",
    "\n",
    "            metric_list.append([r2, mae, r_mse, mape, smape, ood_mae])\n",
    "            pred_list.append([preds, tY_test])\n",
    "            del cpd_s, preds, r2, mae       \n",
    "\n",
    "            # ________________________________________________________________________________________________________________________\n",
    "\n",
    "            ent = EnT(tensor_shape = tensor_shape,\n",
    "                      rank = 5 if dataset == 'lattice' else 32,\n",
    "                      activation = 'relu',\n",
    "                      dropout = [0.2, 0],\n",
    "                      hidden_channels = 7,\n",
    "                      n_decompositions = 10)\n",
    "\n",
    "            ent.train_model(training_sparse_tensor.indices().t(),\n",
    "                            training_sparse_tensor.values(),\n",
    "                            batch_size = 32,\n",
    "                            validation_portion = 0,\n",
    "                            early_stopping = 0,\n",
    "                            n_epochs = 1000, \n",
    "                            lr = 5e-3, \n",
    "                            wd = 5e-3,\n",
    "                            verbose = False)\n",
    "\n",
    "            preds = ent(testing_sparse_tensor.indices().t()).detach().cpu().numpy()\n",
    "            r2 = r2_score(tY_test, preds)\n",
    "            mae = abs(preds - tY_test).mean()\n",
    "            r_mse = (abs((preds - tY_test) ** 2).mean()) ** (1/2)\n",
    "            mape = abs((preds - tY_test) / tY_test).mean()\n",
    "            smape = abs( 2 * ((preds - tY_test) / (abs(tY_test) + abs(preds)))).mean()\n",
    "\n",
    "            ood_preds = ent(tX_test_ood).detach().cpu().numpy()\n",
    "            ood_mae = abs(ood_preds - tY_test_ood).mean()\n",
    "\n",
    "            metric_list.append([r2, mae, r_mse, mape, smape, ood_mae])\n",
    "            pred_list.append([preds, tY_test])\n",
    "            del ent, preds, r2, mae\n",
    "\n",
    "            # ________________________________________________________________________________________________________________________\n",
    "\n",
    "            neat = train_tensor_completion(model_type = 'NeAT',\n",
    "                                        rank = 32,\n",
    "                                        sparse_tensor = training_sparse_tensor,\n",
    "                                        num_epochs = 500,\n",
    "                                        batch_size = 64,\n",
    "                                        loss_p = 2,\n",
    "                                        lr = 1e-3,\n",
    "                                        wd = 1e-4,\n",
    "                                        NeAT_hidden_dim = 32,\n",
    "                                        NeAT_drop = 0.1,\n",
    "                                        NeAT_drop2 = 0.5,\n",
    "                                        val_size = None,\n",
    "                                        early_stopping = False,\n",
    "                                        verbose = False)\n",
    "\n",
    "            preds = neat(testing_sparse_tensor.indices().t()).detach().cpu().numpy()\n",
    "            r2 = r2_score(tY_test, preds)\n",
    "            mae = abs(preds - tY_test).mean()\n",
    "            r_mse = (abs((preds - tY_test) ** 2).mean()) ** (1/2)\n",
    "            mape = abs((preds - tY_test) / tY_test).mean()\n",
    "            smape = abs( 2 * ((preds - tY_test) / (abs(tY_test) + abs(preds)))).mean()\n",
    "\n",
    "            ood_preds = neat(tX_test_ood).detach().cpu().numpy()\n",
    "            ood_mae = abs(ood_preds - tY_test_ood).mean()\n",
    "\n",
    "            metric_list.append([r2, mae, r_mse, mape, smape, ood_mae])\n",
    "            pred_list.append([preds, tY_test])\n",
    "            del neat, preds, r2, mae\n",
    "\n",
    "            # ________________________________________________________________________________________________________________________\n",
    "\n",
    "            xgb = XGBRegressor(n_estimators = 100,\n",
    "                               max_depth = None,\n",
    "                               random_state = random_state)\n",
    "\n",
    "            xgb.fit(X_train, Y_train)\n",
    "            preds = xgb.predict(X_test)\n",
    "            r2 = r2_score(Y_test, preds)\n",
    "            mae = abs(preds - Y_test).mean()\n",
    "            r_mse = (abs((preds - Y_test) ** 2).mean()) ** (1/2)\n",
    "            mape = abs((preds - Y_test) / Y_test).mean()\n",
    "            smape = abs( 2 * ((preds - Y_test) / (abs(Y_test) + abs(preds)))).mean()\n",
    "            \n",
    "            ood_preds = xgb.predict(X_test_ood)\n",
    "            ood_mae = abs(ood_preds - Y_test_ood).mean()\n",
    "\n",
    "            metric_list.append([r2, mae, r_mse, mape, smape, ood_mae])\n",
    "            pred_list.append([preds, Y_test])\n",
    "            del xgb, preds, r2, mae\n",
    "\n",
    "            # ________________________________________________________________________________________________________________________\n",
    "\n",
    "            catb = CatBoostRegressor(iterations = 500,\n",
    "                                     learning_rate = 5e-2,\n",
    "                                     depth = 16,\n",
    "                                     loss_function = 'RMSE',\n",
    "                                     random_state = random_state,\n",
    "                                     verbose = False)\n",
    "\n",
    "            catb.fit(X_train, Y_train)\n",
    "            preds = catb.predict(X_test)\n",
    "            r2 = r2_score(Y_test, preds)\n",
    "            mae = abs(preds - Y_test).mean()\n",
    "            r_mse = (abs((preds - Y_test) ** 2).mean()) ** (1/2)\n",
    "            mape = abs((preds - Y_test) / Y_test).mean()\n",
    "            smape = abs( 2 * ((preds - Y_test) / (abs(Y_test) + abs(preds)))).mean()\n",
    "\n",
    "            ood_preds = catb.predict(X_test_ood)\n",
    "            ood_mae = abs(ood_preds - Y_test_ood).mean()            \n",
    "\n",
    "            metric_list.append([r2, mae, r_mse, mape, smape, ood_mae])\n",
    "            pred_list.append([preds, Y_test])\n",
    "            del catb, preds, r2, mae     \n",
    "\n",
    "            # ________________________________________________________________________________________________________________________\n",
    "\n",
    "            mlp = MLPRegressor(hidden_layer_sizes = (32),\n",
    "                               activation = 'relu',\n",
    "                               learning_rate = 'constant',\n",
    "                               solver = 'adam',\n",
    "                               validation_fraction = 0,\n",
    "                               early_stopping = False,\n",
    "                               random_state = random_state)\n",
    "\n",
    "            mlp.fit(X_train, Y_train)\n",
    "            preds = mlp.predict(X_test)\n",
    "            r2 = r2_score(Y_test, preds)\n",
    "            mae = abs(preds - Y_test).mean()\n",
    "            r_mse = (abs((preds - Y_test) ** 2).mean()) ** (1/2)\n",
    "            mape = abs((preds - Y_test) / Y_test).mean()\n",
    "            smape = abs( 2 * ((preds - Y_test) / (abs(Y_test) + abs(preds)))).mean()\n",
    "\n",
    "            ood_preds = mlp.predict(X_test_ood)\n",
    "            ood_mae = abs(ood_preds - Y_test_ood).mean()\n",
    "\n",
    "            metric_list.append([r2, mae, r_mse, mape, smape, ood_mae])\n",
    "            pred_list.append([preds, Y_test])\n",
    "            del mlp, preds, r2, mae     \n",
    "\n",
    "            # ________________________________________________________________________________________________________________________\n",
    "\n",
    "            kernel = ConstantKernel(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2)) + WhiteKernel(1e-3, (1e-5, 1e1))\n",
    "            gp = GaussianProcessRegressor(kernel = kernel, \n",
    "                                          alpha = 1e-6, \n",
    "                                          n_restarts_optimizer = 3, \n",
    "                                          random_state = random_state)\n",
    "\n",
    "            gp.fit(X_train, Y_train)\n",
    "            preds = gp.predict(X_test)\n",
    "            r2 = r2_score(Y_test, preds)\n",
    "            mae = abs(preds - Y_test).mean()\n",
    "            r_mse = (abs((preds - Y_test) ** 2).mean()) ** (1/2)\n",
    "            mape = abs((preds - Y_test) / Y_test).mean()\n",
    "            smape = abs( 2 * ((preds - Y_test) / (abs(Y_test) + abs(preds)))).mean()\n",
    "\n",
    "            ood_preds = gp.predict(X_test_ood)\n",
    "            ood_mae = abs(ood_preds - Y_test_ood).mean()\n",
    "\n",
    "            metric_list.append([r2, mae, r_mse, mape, smape, ood_mae])\n",
    "            pred_list.append([preds, Y_test])\n",
    "            del gp, preds, r2, mae\n",
    "\n",
    "            # ________________________________________________________________________________________________________________________\n",
    "\n",
    "            rf = RandomForestRegressor(n_estimators = 100, \n",
    "                                       max_depth = None, \n",
    "                                       random_state = random_state)\n",
    "\n",
    "            rf.fit(X_train, Y_train)\n",
    "            preds = rf.predict(X_test)\n",
    "            r2 = r2_score(Y_test, preds)\n",
    "            mae = abs(preds - Y_test).mean()\n",
    "            r_mse = (abs((preds - Y_test) ** 2).mean()) ** (1/2)\n",
    "            mape = abs((preds - Y_test) / Y_test).mean()\n",
    "            smape = abs( 2 * ((preds - Y_test) / (abs(Y_test) + abs(preds)))).mean()\n",
    "\n",
    "            ood_preds = rf.predict(X_test_ood)\n",
    "            ood_mae = abs(ood_preds - Y_test_ood).mean()\n",
    "\n",
    "            metric_list.append([r2, mae, r_mse, mape, smape, ood_mae])\n",
    "            pred_list.append([preds, Y_test])\n",
    "            del rf, preds, r2, mae\n",
    "\n",
    "            # ________________________________________________________________________________________________________________________\n",
    "\n",
    "            svm = SVR(kernel = 'rbf', degree = 3, tol = 1e-4)\n",
    "\n",
    "            svm.fit(X_train, Y_train)\n",
    "            preds = svm.predict(X_test)\n",
    "            r2 = r2_score(Y_test, preds)\n",
    "            mae = abs(preds - Y_test).mean()\n",
    "            r_mse = (abs((preds - Y_test) ** 2).mean()) ** (1/2)\n",
    "            mape = abs((preds - Y_test) / Y_test).mean()\n",
    "            smape = abs( 2 * ((preds - Y_test) / (abs(Y_test) + abs(preds)))).mean()\n",
    "\n",
    "            ood_preds = svm.predict(X_test_ood)\n",
    "            ood_mae = abs(ood_preds - Y_test_ood).mean()\n",
    "\n",
    "            metric_list.append([r2, mae, r_mse, mape, smape, ood_mae])\n",
    "            pred_list.append([preds, Y_test])\n",
    "            del svm, preds, r2, mae\n",
    "\n",
    "            # ________________________________________________________________________________________________________________________\n",
    "\n",
    "            lm = LinearRegression()\n",
    "\n",
    "            lm.fit(X_train, Y_train)\n",
    "            preds = lm.predict(X_test)\n",
    "            r2 = r2_score(Y_test, preds)\n",
    "            mae = abs(preds - Y_test).mean()\n",
    "            r_mse = (abs((preds - Y_test) ** 2).mean()) ** (1/2)\n",
    "            mape = abs((preds - Y_test) / Y_test).mean()\n",
    "            smape = abs( 2 * ((preds - Y_test) / (abs(Y_test) + abs(preds)))).mean()\n",
    "\n",
    "            ood_preds = lm.predict(X_test_ood)\n",
    "            ood_mae = abs(ood_preds - Y_test_ood).mean()\n",
    "\n",
    "            metric_list.append([r2, mae, r_mse, mape, smape, ood_mae])\n",
    "            pred_list.append([preds, Y_test])\n",
    "            del lm, preds, r2, mae\n",
    "\n",
    "            # ________________________________________________________________________________________________________________________\n",
    "\n",
    "            it_list.append(metric_list)\n",
    "            pred_it_list.append(pred_list)\n",
    "\n",
    "            if it == len(train_test_splits)-1: print(it+1, '\\n')\n",
    "            else: print(it+1, end = \", \")\n",
    "\n",
    "        all_results.append(it_list)\n",
    "        all_preds.append(pred_it_list)\n",
    "\n",
    "    all_results = np.stack(all_results)\n",
    "    print(\"All done!\")\n",
    "\n",
    "    return all_results, all_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b402bc",
   "metadata": {},
   "source": [
    "### Display Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4da898b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: cogni_spin\n",
      "Iteration: 1, 2, 3 \n",
      "\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "all_results, all_preds = get_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557882e1",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cfc10c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R²</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>sMAPE</th>\n",
       "      <th>OOD MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CPD</th>\n",
       "      <td>-0.283</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.263</td>\n",
       "      <td>2.727</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CPD-S</th>\n",
       "      <td>-0.238</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.257</td>\n",
       "      <td>2.067</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoSTCo</th>\n",
       "      <td>0.166</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.220</td>\n",
       "      <td>2.277</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeAT</th>\n",
       "      <td>-0.514</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.232</td>\n",
       "      <td>6.835</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.244</td>\n",
       "      <td>2.445</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>0.375</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.206</td>\n",
       "      <td>2.286</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>-0.804</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.265</td>\n",
       "      <td>5.971</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.234</td>\n",
       "      <td>2.527</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.077</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.225</td>\n",
       "      <td>2.547</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>-0.364</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.235</td>\n",
       "      <td>6.011</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>-0.268</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.232</td>\n",
       "      <td>4.082</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             R²    MAE   RMSE   MAPE  sMAPE  OOD MAE\n",
       "CPD      -0.283  0.114  0.263  2.727  0.940    0.122\n",
       "CPD-S    -0.238  0.107  0.257  2.067  0.641    0.116\n",
       "CoSTCo    0.166  0.094  0.220  2.277  0.645    0.102\n",
       "NeAT     -0.514  0.115  0.232  6.835  0.798    0.125\n",
       "XGBoost  -0.003  0.104  0.244  2.445  0.585    0.115\n",
       "CatBoost  0.375  0.089  0.206  2.286  0.570    0.097\n",
       "MLP      -0.804  0.139  0.265  5.971  0.963    0.149\n",
       "GP        0.011  0.106  0.234  2.527  0.856    0.116\n",
       "RF        0.077  0.103  0.225  2.547  0.593    0.113\n",
       "SVM      -0.364  0.128  0.235  6.011  0.872    0.136\n",
       "LR       -0.268  0.117  0.232  4.082  0.724    0.127"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_colors = {\n",
    "    'CPD':'deepskyblue',\n",
    "    'CPD-S':'orangered',\n",
    "    'CoSTCo':'limegreen',\n",
    "    'NeAT':'magenta',\n",
    "    'XGBoost':'gray',\n",
    "    'CatBoost':'gray',\n",
    "    'MLP':'gray',\n",
    "    'GP':'gray',\n",
    "    'RF':'gray',\n",
    "    'SVM':'gray',\n",
    "    'LR':'gray'\n",
    "    }\n",
    "\n",
    "models = list(models_colors.keys())\n",
    "colors = list(models_colors.values())\n",
    "pd.DataFrame(all_results[0].mean(axis = 0).round(3),\n",
    "             columns = ['R²', 'MAE', 'RMSE', 'MAPE', 'sMAPE', 'OOD MAE'],\n",
    "             index = models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb1956aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_i = 2\n",
    "# it_i = 0\n",
    "# len(all_preds[dataset_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d27f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_order = ['R²', 'MAE', 'OOD MAE', 'MAPE']\n",
    "model_order = ['LR', 'SVM', 'RF', 'XGBoost', 'CatBoost', 'GP', 'MLP', \n",
    "               'CPD', 'CPD-S', 'NeAT', 'CoSTCo']\n",
    "\n",
    "mega_df = list()\n",
    "for dataset_results in all_results:\n",
    "\n",
    "    latex_df = list()\n",
    "    for metr_c in range(dataset_results.shape[2]):\n",
    "        if metr_c == 0: \n",
    "            arr = dataset_results[:, :, metr_c].mean(axis = 0)\n",
    "            u = np.unique(arr)\n",
    "            best, best2 = u[-1], u[-2]\n",
    "        else: \n",
    "            arr = dataset_results[:, :, metr_c].mean(axis = 0)\n",
    "            u = np.unique(arr)\n",
    "            best, best2 = u[0], u[1]\n",
    "\n",
    "        latex_df_row = list()\n",
    "        for model_r in range(dataset_results.shape[1]):\n",
    "\n",
    "            entry_mean = dataset_results[:, model_r, metr_c].mean()\n",
    "            entry_std = dataset_results[:, model_r, metr_c].std()\n",
    "\n",
    "            if entry_mean.round(2) == best.round(2): entry_str = \"\\\\textbf{\" + f\"{entry_mean:.2f} ± {entry_std:.1f}\" + \"}\"\n",
    "            elif entry_mean.round(2) == best2.round(2): entry_str = \"\\\\underline{\" + f\"{entry_mean:.2f} ± {entry_std:.1f}\" + \"}\"\n",
    "            else: entry_str = f\"{entry_mean:.2f} ± {entry_std:.1f}\"\n",
    "\n",
    "            latex_df_row.append(entry_str)\n",
    "        latex_df.append(latex_df_row)\n",
    "\n",
    "    metric_names = ['R²', 'MAE', 'RMSE', 'MAPE', 'sMAPE', 'OOD MAE']\n",
    "    latex_df = pd.DataFrame(np.stack(latex_df).T,\n",
    "                            index = models,\n",
    "                            columns = metric_names)\n",
    "\n",
    "    latex_df = latex_df[metric_order]\n",
    "\n",
    "    mega_df.append(latex_df)\n",
    "\n",
    "mega_df = pd.concat(mega_df, axis = 1)\n",
    "mega_df = mega_df.loc[model_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79d26988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{r|cccc|cccc|cccc}\n",
      "\\toprule\n",
      "\\multicolumn{1}{c}{} & \\multicolumn{4}{c}{Lattice Dataset} & \\multicolumn{4}{c}{Crossed Barrel Dataset} & \\multicolumn{4}{c}{Cogni-e-Spin Dataset} \\\n",
      " & R² & MAE & OOD MAE & MAPE \\\\\n",
      "\\midrule\n",
      "LR & -0.27 ± 0.7 & 0.12 ± 0.1 & 0.13 ± 0.1 & 4.08 ± 2.2 \\\\\n",
      "SVM & -0.36 ± 0.8 & 0.13 ± 0.1 & 0.14 ± 0.1 & 6.01 ± 4.2 \\\\\n",
      "RF & 0.08 ± 0.2 & 0.10 ± 0.1 & 0.11 ± 0.1 & 2.55 ± 1.3 \\\\\n",
      "XGBoost & -0.00 ± 0.2 & 0.10 ± 0.1 & 0.12 ± 0.1 & 2.45 ± 0.6 \\\\\n",
      "CatBoost & \\textbf{0.37 ± 0.1} & \\textbf{0.09 ± 0.1} & \\textbf{0.10 ± 0.1} & 2.29 ± 1.3 \\\\\n",
      "GP & 0.01 ± 0.4 & 0.11 ± 0.1 & 0.12 ± 0.1 & 2.53 ± 2.0 \\\\\n",
      "MLP & -0.80 ± 1.1 & 0.14 ± 0.1 & 0.15 ± 0.1 & 5.97 ± 3.5 \\\\\n",
      "\\midrule\n",
      "CPD & -0.28 ± 0.3 & 0.11 ± 0.1 & 0.12 ± 0.1 & 2.73 ± 1.5 \\\\\n",
      "CPD-S & -0.24 ± 0.3 & 0.11 ± 0.1 & 0.12 ± 0.1 & \\textbf{2.07 ± 1.0} \\\\\n",
      "NeAT & -0.51 ± 1.2 & 0.12 ± 0.1 & 0.13 ± 0.1 & 6.84 ± 6.2 \\\\\n",
      "CoSTCo & \\underline{0.17 ± 0.1} & \\textbf{0.09 ± 0.1} & \\textbf{0.10 ± 0.1} & \\underline{2.28 ± 1.1} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_str = mega_df.to_latex()\n",
    "latex_str = '\\n'.join(['\\\\begin{tabular}{r|cccc|cccc|cccc}'] + \n",
    "                      latex_str.split('\\n')[1:2] + \n",
    "                      ['\\multicolumn{1}{c}{} & \\multicolumn{4}{c}{Lattice Dataset} & \\multicolumn{4}{c}{Crossed Barrel Dataset} & \\multicolumn{4}{c}{Cogni-e-Spin Dataset} \\\\'] +\n",
    "                      latex_str.split('\\n')[2:11] + \n",
    "                      ['\\\\midrule'] + latex_str.split('\\n')[11:])\n",
    "print(latex_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a947c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parity_plot(dataset_i, model_i, it_i = 0, title = False, figsize = (10, 6), metrics = ['r2', 'r']):\n",
    "\n",
    "    preds  = all_preds[dataset_i][it_i][model_i][0]\n",
    "    Y_test = all_preds[dataset_i][it_i][model_i][1]\n",
    "\n",
    "    r2 = r2_score(Y_test, preds)\n",
    "    r, pv = pearsonr(Y_test, preds)\n",
    "    mae = abs(Y_test - preds).mean()\n",
    "    rmse = np.sqrt( ((Y_test - preds) ** 2).mean() )\n",
    "    mape = abs((Y_test - preds)/Y_test).mean()\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.scatter(Y_test, preds, color = 'limegreen', edgecolors = 'black')\n",
    "\n",
    "    min_val = min(Y_test.min(), preds.min())\n",
    "    max_val = max(Y_test.max(), preds.max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], color = 'black', linestyle=\"-\", lw = 2, zorder = 0)\n",
    "\n",
    "    plt.xlabel(\"True values\", fontsize = 16)\n",
    "    plt.ylabel(\"Predicted values\", fontsize = 16)\n",
    "    \n",
    "    if title: plt.title(f\"Dataset: {datasets[dataset_i]} | Model: {models[model_i]} | Iteration: {it_i}\", fontsize = 20)\n",
    "\n",
    "    textstr = (\n",
    "        f\"R² = {r2:.3f}\\nr = {r:.3f}\"\n",
    "    )\n",
    "    \n",
    "    textstr = \"\"\n",
    "    if 'r2' in metrics: textstr += f\"R² = {r2:.3f}\\n\"\n",
    "    if 'r' in metrics: textstr += f\"r = {r:.3f}\\n\"\n",
    "    if 'mae' in metrics: textstr += f\"MAE = {mae:.3f}\\n\"\n",
    "    if 'rmse' in metrics: textstr += f\"RMSE = {rmse:.3f}\\n\"\n",
    "    if 'mape' in metrics: textstr += f\"MAPE = {mape:.3f}\\n\"\n",
    "    textstr = textstr[:-1]\n",
    "\n",
    "\n",
    "    plt.text(\n",
    "        0.21 + (0.03 * ('mape' in metrics or 'rmse' in metrics)), 0.96, textstr,\n",
    "        transform=plt.gca().transAxes,\n",
    "        fontsize=20,\n",
    "        verticalalignment=\"top\",\n",
    "        horizontalalignment=\"right\",\n",
    "        bbox=dict(\n",
    "            boxstyle=\"round,pad=0.3\",\n",
    "            facecolor=\"white\",\n",
    "            edgecolor=\"black\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2c268bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CPD',\n",
       " 'CPD-S',\n",
       " 'CoSTCo',\n",
       " 'NeAT',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'MLP',\n",
       " 'GP',\n",
       " 'RF',\n",
       " 'SVM',\n",
       " 'LR']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c12ec711",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m figsize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m      4\u001b[0m metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmape\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m \u001b[43mparity_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_i\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mit_i\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mit_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m parity_plot(dataset_i, model_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m, it_i \u001b[38;5;241m=\u001b[39m it_i, title \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, figsize \u001b[38;5;241m=\u001b[39m figsize, metrics \u001b[38;5;241m=\u001b[39m metrics)\n",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m, in \u001b[0;36mparity_plot\u001b[0;34m(dataset_i, model_i, it_i, title, figsize, metrics)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparity_plot\u001b[39m(dataset_i, model_i, it_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, title \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, figsize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m), metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m----> 3\u001b[0m     preds  \u001b[38;5;241m=\u001b[39m \u001b[43mall_preds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_i\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mit_i\u001b[49m\u001b[43m]\u001b[49m[model_i][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m     Y_test \u001b[38;5;241m=\u001b[39m all_preds[dataset_i][it_i][model_i][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      6\u001b[0m     r2 \u001b[38;5;241m=\u001b[39m r2_score(Y_test, preds)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "it_i = 6\n",
    "dataset_i = 0\n",
    "figsize = (10, 6)\n",
    "metrics = ['r2', 'mae', 'rmse', 'mape']\n",
    "\n",
    "parity_plot(dataset_i, model_i = 2, it_i = it_i, title = True, figsize = figsize, metrics = metrics)\n",
    "parity_plot(dataset_i, model_i = -3, it_i = it_i, title = True, figsize = figsize, metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb19c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065dd533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
